# 100DaysOfMLCode
This repository contains the #100DaysOfML challege undertaken by me starting 7th Jan 2019.

# Day 1:
7/1/2019
I resumed the Convolutional neural networks course on deeplearning.ai. Into week 3 of the course now.

# Day 2:
8/1/2019
I decided to learn about data cleaning before it goes into analysis pipeline, so I made a notebook of various techniques utilized in data preprocessing.

# Day 3:
9/1/2019
Finished up on making the notebook, I shifted my focus on revising basics of  Git and Github by finishing first 2 important lessons on Udacity's Git and Github course. This should help me more with this repository! [Commit](https://github.com/AtharvaPagare/Data-Preprocessing/blob/master/Data-Preprocessing.ipynb).

# Day 4:
10/1/2019
Finished with basics of Git and Github course. I also finished learning the details of exploratory data analysis with the help of ths course - https://www.coursera.org/learn/data-analysis-with-python/home

# Day 5:
11/01/2019
Revised concepts of Regression and Regularization with a notebook. Also learned about various seaborn plotting function for continous and categorical feature selection.

# Day 6:
12/01/2019
Started with IBM specialization in [Data Science - Data Visualization in python course](https://www.coursera.org/learn/python-for-data-visualization/). Into week three now. This course is very helpful to clear my concepts in data visualisation.

# Day 7:
13/01/2019
Finished with the [Data Visualisation course](https://www.coursera.org/learn/python-for-data-visualization/). Also started with [Titanic Dataset Challenge on Kaggle](https://www.kaggle.com/c/titanic) - finished with data prepreocessing, into data visualisation part now, hopefully will start modelling soon.

# Day 8:
14/01/2019
Started the modelling part of the [Titanic Dataset Challenge on Kaggle](https://www.kaggle.com/c/titanic). This enabled me revise the concepts of various classification algorithms.

# Day 9
15/01/2019
Applied bunch of classification algorithms to the Titanic dataset. Found out that support vector machines gave the best accuracy using cross validation, the final score improved accuracy more than 6% than my last submission (which I made months ago). Will try to implement some more algorithms.
