# 100DaysOfMLCode
This repository contains the #100DaysOfML challege undertaken by me starting 7th Jan 2019.

# Day 1:
7/1/2019
I resumed the Convolutional neural networks course on deeplearning.ai. Into week 2 of the course now.

# Day 2:
8/1/2019
I decided to learn about data cleaning before it goes into analysis pipeline, so I made a notebook of various techniques utilized in data preprocessing.

# Day 3:
9/1/2019
Finished up on making the notebook, I shifted my focus on revising basics of  Git and Github by finishing first 2 important lessons on Udacity's Git and Github course. This should help me more with this repository! [Commit](https://github.com/AtharvaPagare/Data-Preprocessing/blob/master/Data-Preprocessing.ipynb).

# Day 4:
10/1/2019
Finished with basics of Git and Github course. I also finished learning the details of exploratory data analysis with the help of ths course - https://www.coursera.org/learn/data-analysis-with-python/home

# Day 5:
11/01/2019
Revised concepts of Regression and Regularization with a notebook. Also learned about various seaborn plotting function for continous and categorical feature selection.

# Day 6:
12/01/2019
Started with IBM specialization in [Data Science - Data Visualization in python course](https://www.coursera.org/learn/python-for-data-visualization/). Into week three now. This course is very helpful to clear my concepts in data visualisation.

# Day 7:
13/01/2019
Finished with the [Data Visualisation course](https://www.coursera.org/learn/python-for-data-visualization/). Also started with [Titanic Dataset Challenge on Kaggle](https://www.kaggle.com/c/titanic) - finished with data prepreocessing, into data visualisation part now, hopefully will start modelling soon.

# Day 8:
14/01/2019
Started the modelling part of the [Titanic Dataset Challenge on Kaggle](https://www.kaggle.com/c/titanic). This enabled me revise the concepts of various classification algorithms.

# Day 9
15/01/2019
Applied bunch of classification algorithms to the Titanic dataset. Found out that support vector machines gave the best accuracy using cross validation, the final score improved accuracy more than 6% than my last submission (which I made months ago). Will try to implement some more algorithms.

# Day 10
16/01/2019
Learned various types of Ensemble methods especially - Random Forest, Voting Classifier, Extra Trees. Also went through the mathematics of Support Vector Machines.

# Day 11
17/01/2019
Continued learning concepts of ensemble methods learning.

# Day 12 
18/01/2019
Referred to some concepts regarding Exploratory Data Analysis. Also learning about various metrics to determine the quality of a machine learning model.

# Day 13
19/01/2019
Implemented voting classifier to Titanic Dataset but did not achieve a better performance than Rbf kernel based SVM. Will try to continue efforts towards Titanic Dataset, but for now I have turned my attention back to convolutional neural networks. Went through [AlexNet Research Paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).

# Day 14 
20/01/2019
Learned about keras framework and also implemented Resnet-50 model in keras. Completed week 2 of deeplearning.ai couse on Convolutional neural network. 

# Day 15
21/01/2019
Learned about YOLO(You Only Look Once) Object Detection Algorithm. Starting to implement it in keras in the course's programming assignnment.
